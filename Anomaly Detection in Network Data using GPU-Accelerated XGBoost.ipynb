{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"> <img src=\"images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection in Network Data using GPU-Accelerated XGBoost\n",
    "\n",
    "- Ananth Sankar, Solutions Architect at NVIDIA.\n",
    "- Eric Harper, Solutions Architect, Global Telecoms at NVIDIA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As network traffic continues to grow exponentially, the number of network attacks and the different kinds of attacks is also growing. The ability to quickly and frequently train machine learning models to detect network intrusions is more important now than ever.\n",
    "\n",
    "In this series of labs, we will learn how to use machine learning and deep learning models for detecting network intrusions in the full KDD99 dataset. The data processing and model training techniques that will be learned in these labs can be applied to many datasets for anomaly detection problems.\n",
    "\n",
    "The KDD99 dataset consists of normal data points and points that have been labeled as Denial of Service (DoS), Remote to User (R2L), User to Root (U2R), and Probing (Probe) by logging network packet information. More information about the dataset can be found at https://kdd.ics.uci.edu/databases/kddcup99/task.html. \n",
    "\n",
    "\n",
    "We'll start off by exploring the dataset and then we will use the NVIDIA RAPIDS library to train GPU-accelerated XGBoost models for network intrusion detection. The RAPIDS suite of software libraries, built on CUDA-X AI, gives you the freedom to execute end-to-end data science and analytics pipelines entirely on GPUs. It relies on NVIDIA® CUDA® primitives for low-level compute optimization, but exposes that GPU parallelism and high-bandwidth memory speed through user-friendly Python interfaces.\n",
    "\n",
    "Notice that we will also be using the Pandas and Scikit-learn packages in this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries that will be needed for the lab\n",
    "\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import gc\n",
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "from time import time\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix,accuracy_score,classification_report,roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from timeit import default_timer\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Set the seed for numpy\n",
    "np.random.seed(123)\n",
    "\n",
    "# Display all columns of Pandas' dataframes by default\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data_path = './data/kddcup.data.corrected'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by first importing the KDD99 Dataset using Pandas and then doing some basic data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\"logged_in\",\n",
    "             \"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "             \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "             \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\n",
    "             \"dst_host_same_src_port_rate\",\"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\n",
    "             \"dst_host_srv_rerror_rate\",\"label\"]\n",
    "\n",
    "df =  pd.read_csv(data_path, header=None, names=col_names, index_col=False)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of the KDD Cup 99 dataset is a network connection, with a total of 41 independent variables and 1 dependent variable. The independent variables can be broadly divided into three groups:\n",
    "\n",
    "1. Basic input features of network connections such as duration, protocol type, and number of bytes from source IP addresses \n",
    "2. Content input features of network connections\n",
    "3. The statistical input features computed over a time window\n",
    "\n",
    "Scroll to the right of the above cell to see all of the features.  The last column on the right is the \"Label\" column. This indicates whether the row is normal or some type of anomalous network traffic.\n",
    "\n",
    "Let's see what types of anomalies are in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we train a label encoder so that we can map our classes to integers later for model training\n",
    "le = LabelEncoder()\n",
    "le.fit(df.label)\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Dataset Modification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dataset has more anomalies than normal data. Reflect for a moment about the implications of having more anomalies might be. Reflect either here in the notebook, on a piece of paper, or with a peer sitting next to you."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Reflection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll come back to test your hypothesis shortly. \n",
    "\n",
    "<a id='return'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train an XGBoost model, we have to encode the strings in categorical variables to numeric terms. \n",
    "\n",
    "We will use one-hot encoding to translate each of the 7 categorical features:  `protocol type`, `service`, `flag`, `land`, `logged_in`, `is_host_login`, `is_guest_login` using the Pandas function `get_dummies()`. One-hot encoding will transform the categorical variable into a numerical variable for each category. If a category takes ten values, then that categorical variable will be transformed into 10 numerical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 One-hot Encode the Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture the categorical variables and one-hot encode them\n",
    "cat_vars = ['protocol_type', 'service', 'flag', 'land', 'logged_in','is_host_login', 'is_guest_login']\n",
    "\n",
    "# find unique labels for each category\n",
    "cat_data = pd.get_dummies(df[cat_vars])\n",
    "\n",
    "# check that the categorical variables were created correctly\n",
    "cat_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Scroll to the right to notice the new categories that were created. For example, the categorical variable \"protocol_type\" is split into three categories, protocol_type_icmp, protocol_type_tcp and protocol_type_udp. Now that the one hot encoding of the categorical data is done, we need to merge the numerical data from the original data. \n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_vars = list(set(df.columns.values.tolist()) - set(cat_vars))\n",
    "numeric_vars.remove('label')\n",
    "numeric_data = df[numeric_vars].copy()\n",
    "\n",
    "# check that the numeric data has been captured accurately\n",
    "numeric_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat numeric and the encoded categorical variables\n",
    "numeric_cat_data = pd.concat([numeric_data, cat_data], axis=1)\n",
    "\n",
    "# here we do a quick sanity check that the data has been concatenated correctly by checking the dimension of the vectors\n",
    "print(cat_data.shape)\n",
    "print(numeric_data.shape)\n",
    "print(numeric_cat_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Now let's split the data into training set and test set in the ratio of 75:25. We will be using <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\">LabelEncoder</a>, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.fit_transform\">fit_transform</a> and <a href=\"https://scikit-https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">train_test_split</a> from scikit-learn.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture the labels\n",
    "labels = df['label'].copy()\n",
    "\n",
    "# convert labels to integers\n",
    "integer_labels = le.transform(labels)\n",
    "\n",
    "# split data into test and train\n",
    "x_train, x_test, y_train, y_test = train_test_split(numeric_cat_data,\n",
    "                                                    integer_labels,\n",
    "                                                    test_size=.25, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "We can inspect the dimension of the testing set and the training set to confirm that the data has been split correctly. We will also save the dataset to be used in the later portion of this lab and in lab-2 by \"pickling\" the data. Pickling allows us to save a python object as a binary file.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the dimensions of our train and test sets are okay\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the datasets for later use\n",
    "preprocessed_data = {\n",
    "    'x_train':x_train,\n",
    "    'y_train':y_train,\n",
    "    'x_test':x_test,\n",
    "    'y_test':y_test,\n",
    "    'le':le\n",
    "}\n",
    "\n",
    "# pickle the preprocessed_data\n",
    "path = 'preprocessed_data_full.pkl'\n",
    "out = open(path, 'wb')\n",
    "pickle.dump(preprocessed_data, out)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will approach this anomaly detection problem in two ways:\n",
    "\n",
    "1. Implementing binary classification where we will label the Normal frames as '0' and Anomalous frames as '1' and use a 'one vs all' approach to detect an anomalous frame\n",
    "2. Implementing multi-class classification where we will be able to detect the *type* of anomaly as well using our original y_train and y_test labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Training a Binary Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, you will convert to binary labels. Remember what you do here as you will implement the multi-class solution yourself later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_to_binary(label_encoder, labels):\n",
    "    normal_idx = np.where(label_encoder.classes_ == 'normal.')[0][0]\n",
    "    my_labels = labels.copy()\n",
    "    my_labels[my_labels != normal_idx] = 1 \n",
    "    my_labels[my_labels == normal_idx] = 0\n",
    "    return my_labels\n",
    "\n",
    "binary_y_train = convert_label_to_binary(le, y_train)\n",
    "binary_y_test = convert_label_to_binary(le, y_test)\n",
    "\n",
    "# check how many anomalies are in our labels\n",
    "print('Number of anomalies in y_train: ', binary_y_train.sum())\n",
    "print('Number of anomalies in y_test:  ', binary_y_test.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the anomalies are optimally split between the training set and the testing set. Now that we have prepared the data, we are ready to train an XGBoost model to detect anomalies. \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Training GPU XGBoost Models with RAPIDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is widely known today as a \"go to\" model when working with structured data such as the KDD99 dataset. In fact, there are a disproportionately large number of XGBoost-based winning entries of Kaggle competitions.\n",
    "\n",
    "What is XGBoost and why is it so popular?\n",
    "\n",
    "Traditionally, in tree-based ensemble methods such as Random Forests, we train each tree independently. The predictions of multiple trees are summed to obtain the final score. The figure below classifies whether someone would like to play computer games or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/twocart.png\" alt=\"Alt text that describes the graphic\" title=\"Title text\" width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"color:gray;\">\n",
    "    <em>Image courtesy <a href=\"https://goo.gl/eTxVtA\">goo.gl/eTxVtA<a/></em>\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of XGBoost, an implementation of Gradient Boosted Decision Trees, we repeatedly build new models and combine them into an ensemble. Unlike Random Forests, we build trees one at a time, where each new tree helps to correct errors made by previously trained tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1WDN-kDMOsIhY3vWy8UBOR0qgBRHqbf-2\" alt=\"Alt text that describes the graphic\" title=\"Title text\" width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The objective of the XGBoost model is as follows:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/xgboost-objective.PNG alt=\"Alt text that describes the graphic\" title=\"Title text\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function controls the predictive power of the model, and the XGBoost regularization term ensures simplicity and manages overfitting.\n",
    "\n",
    "Since Boosting focuses step by step on the difficult examples it gives it a nice strategy to deal with unbalanced datasets by strengthening the impact of the positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Why Use GPU to Accelerate XGBoost?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, GPU accelerated XGBoost models will train much faster. It's also extremely easy.  In order to use the GPU version of XGBoost, only one parameter in the code has to be set (see below): ```{'tree_method': 'gpu_hist'```} Also, the environment must have the GPU version of XGBoost: https://xgboost.readthedocs.io/en/latest/gpu/index.html. The easiest way to use GPU XGBoost is to use NVIDIA's RAPIDS container: https://hub.docker.com/r/rapidsai/rapidsai/. \n",
    "\n",
    "Machine learning models using XGBoost on large datasets can take several hours to train and achieve the best predictions. Oftentimes, models have to be trained for 1000s of iterations, and usually many different combinations of hyperparameters must be tested.\n",
    "\n",
    "The more models that can be trained, the better the accuracy will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/moremodels.PNG alt=\"Alt text that describes the graphic\" title=\"Title text\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, the XGBoost algorithm is highly parallelizable by virtue of requiring scans across gradient values and using these partial sums to evaluate the quality of splits at every possible split in the training set. By utilizing fast parallel prefix operations to scan through all possible splits as well as parallel radix sorting to repartition data, the GPU accelerated version builds a decision tree for a given boosting iteration one level at a time, processing the entire dataset concurrently on the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters can have a huge impact on the performance of XGBoost models.\n",
    "Some of the more important ones are listed below. See [here](https://xgboost.readthedocs.io/en/latest/parameter.html) for a description of all parameters and see [here](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html) for a guide to tuning XGBoost models. Feel free to try out different combinations: \n",
    "<ul>\n",
    "<li>\n",
    "<b>objective:</b>\n",
    "Depending on whether we treat our problem as a binary classification problem or as a multi-class classification problem this parameter would be either binary:logistic or multi:softmax respectively.\n",
    "    </li>\n",
    "<li>\n",
    "<b>tree_method:</b>\n",
    "gpu_exact to use the GPU optimized exact greedy algorithm and gpu_hist to use the histogram optimized approximate greedy algorithm. For GPU accelerated XGBoost it is best to use gpu_hist.\n",
    "    </li>\n",
    "<li>\n",
    "<b>n_gpus:</b>\n",
    "The number of GPUs to use for training.  Note, if using GPU DASK, n_gpus should be set to 1.\n",
    "    </li>\n",
    "    \n",
    "<li>\n",
    "<b>max_depth:</b>\n",
    "Increasing this value will give the model more capacity to learn and it will also be more likely to overfit. If using a large max_depth value, make sure to increase the regularization.\n",
    "</li>\n",
    "\n",
    "<li>\n",
    "<b>learning_rate:</b>\n",
    "Used to control the weighting of new trees added to the model. If using a low value here, then the number of rounds of training should be high.\n",
    "</li>\n",
    "\n",
    "<li>\n",
    "<b>num_class:</b>\n",
    "    Indicates the number of classes in the label column. For a binary classification problem this should be 2 and the number of classes in the case of a multi-class problem.\n",
    "</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_rounds':        10,\n",
    "    'max_depth':         8,\n",
    "    'max_leaves':        2**8,\n",
    "    'alpha':             0.9,\n",
    "    'eta':               0.1,\n",
    "    'gamma':             0.1,\n",
    "    'learning_rate':     0.1,\n",
    "    'subsample':         1,\n",
    "    'reg_lambda':        1,\n",
    "    'scale_pos_weight':  2,\n",
    "    'tree_method':       'gpu_hist',\n",
    "    'n_gpus':            1,\n",
    "    'objective':         'binary:logistic',\n",
    "    'verbose':           True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Binary Classification Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the feature and label columns of our training set before we start training our XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, label=binary_y_train)\n",
    "dtest = xgb.DMatrix(x_test, label=binary_y_test)\n",
    "evals = [(dtest, 'test',), (dtrain, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = params['num_rounds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(params, dtrain, num_rounds, evals=evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `nvidia-smi` shell command to see that data has been moved automatically to the GPU for training. Note the memory utilization under the column *Memory-Usage* after running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Testing and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you scroll to the section where we declared our XGboost parameters, we see that we have set the objective to be `binary:logistic`.\n",
    "\n",
    "In a binary logistic classifier we usually set the threshold at 0.5 meaning all probability scores >= 0.5 will be assigned 1 (Anomaly) and those with scores < 0.5 will be assigned 0 (Normal).\n",
    "\n",
    "This will help us calculate the accuracy as we will see in the coming sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's look at our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = .5\n",
    "true_labels = binary_y_test.astype(int)\n",
    "true_labels.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the test set using our trained model\n",
    "preds = model.predict(dtest)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = (preds > threshold).astype(int)\n",
    "print(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Area under the Curve (AUC)\n",
    "\n",
    "The area under the ROC curve is a great metric for determining how well your classification model is performing, even in the case of imbalanced classes. A score of 1 means your model is performing perfectly, while a score of .5 means that your model is the same as randomly guessing. [See here for more information](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the auc\n",
    "auc = roc_auc_score(true_labels, preds)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should be getting near a perfect score here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Accuracy\n",
    "Accuracy is the ratio of correct classifications to the total number of samples.  Accuracy is often misleading in anomaly detection problems where the classes are highly imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Accuracy:', accuracy_score(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy should be almost perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Confusion Matrix represents the quality of the output of a classifier on any dataset. The diagonal elements represent correct or true labels, whereas the off-diagonal (white box in Figures 5 and 6) elements represent the elements misclassified by the classification model. Therefore, the higher the values of the diagonal elements of the confusion matrix, the better and more accurate the classification model becomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = confusion_matrix(true_labels, pred_labels) \n",
    "\n",
    "print ('Confusion Matrix :')\n",
    "\n",
    "def plot_confusion_matrix(cm, target_names, title='Confusion Matrix', cmap=plt.cm.Greens):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    width, height = cm.shape\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            plt.annotate(str(cm[x][y]), xy=(y, x), \n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "\n",
    "\n",
    "plot_confusion_matrix(results, ['Normal','Anomaly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix we can see that our model is performing really well.  It is able to classify almost all of the anomalies.  And this is without any tuning of XGBoost.  We can see why XGBoost is so popular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 AUC Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC curve is a plot of the True Positive Rate (TPR) against the False Positive Rate (FPR). The TPR is a measure of how often the prediction is correct, when there is a positive value, and the FPR is how often the prediction is incorrect when the value is in fact negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(true_labels, pred_labels)\n",
    "roc_auc = roc_auc_score(true_labels, pred_labels)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closer the curve is to the left-hand and the top-hand borders of the ROC plotting area, the better the model is performing over all thresholds. The area under the ROC curve (AUC) is a way of quantifying this performance. 1 is a perfect score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 Model Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is our model performing so well? One tool we can use from XGBoost is the feature importance.  XGBoost will rank the features that it uses in determining a classification.  We can visualize the feature importance using the \"plot_importance\" method.  \n",
    "\n",
    "Knowing which features are contributing the model can be really useful for solving business problems.  In the case of network security, those features can give us way to possibly preempt malicious activity.\n",
    "\n",
    "Feature importance can also be a great way to debug your model. \n",
    "\n",
    "You might have to run this cell twice to see the feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = xgb.plot_importance(model)\n",
    "fig = ax.figure\n",
    "fig.set_size_inches(10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Impact of Skewed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we prepared our data, we pointed out that there were more anomalies than normal data and considered the implications of this dataset skew that doesn't match the real world. Take a moment now see how adjusting our dataset impacts performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_anomalies(df, pct_anomalies=.01):\n",
    "    labels = df['label'].copy()\n",
    "    is_anomaly = labels != 'normal.'\n",
    "    num_normal = np.sum(~is_anomaly)\n",
    "    num_anomalies = int(pct_anomalies * num_normal)\n",
    "    all_anomalies = labels[labels != 'normal.']\n",
    "    anomalies_to_keep = np.random.choice(all_anomalies.index, size=num_anomalies, replace=False)\n",
    "    anomalous_data = df.iloc[anomalies_to_keep].copy()\n",
    "    normal_data = df[~is_anomaly].copy()\n",
    "    new_df = pd.concat([normal_data, anomalous_data], axis=0)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = reduce_anomalies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what anomalies we have after the reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to [data preprocessing](#return) and rerun cells to this point, comparing and contrasting performance. Again, reflect below, on paper, or with a peer. Reflect on *why* the reduction of anomalies had the impact that it did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the impact of reducing anomalies in the dataset and why do you think that is?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4:  Multi-Class Classification Model [Exercise]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen that XGBoost can identify anomalies in the KDD99 dataset really easily.  Let's see if XGBoost can detect the different types of anomalies.  To do that we will train a multi-classification model.\n",
    "\n",
    "We'll point out the difference, then have you implement the pieces that are the same using the binary classifier as a model.\n",
    "\n",
    "For multi-classification models, the labels have to be converted to integers (we've already done this) and the 'objective\n",
    "' and 'num_class' parameters must be changed accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(le.classes_)\n",
    "params['objective'] = 'multi:softprob'\n",
    "params['num_class'] = num_labels\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the field below, set up `dtrain`, `dtest`, `evals`, and `model` as exemplified when we trained our binary classifier. \n",
    "\n",
    "Note: Multiclass labels are in y_train and y_test. Hint: Control F will help you find `dtrain`, `dtest`, `evals` and `model`.\n",
    "\n",
    "You can see how adding multiple classes doesn't increase the complexity in training this type of model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "\n",
    "dtrain = ##SEE BINARY CLASSIFIER FOR HINT##\n",
    "dtest = ##SEE BINARY CLASSIFIER FOR HINT##\n",
    "evals = ##SEE BINARY CLASSIFIER FOR HINT##\n",
    "model = ##SEE BINARY CLASSIFIER FOR HINT##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Testing and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us again evaluate our model on the test set and see how it performs. Note that accuracy now is a metric of how well we do on each of the 23 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Accuracy Score :', accuracy_score(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should be able to get near perfect accuracy. Let's look at the confusion matrix to make sure that we are detecting the anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "print ('Confusion Matrix :')\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Greens):\n",
    "    plt.figure(figsize=(10,10),)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    #tick_marks = np.arange(len(target_names))\n",
    "    #plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    #plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    width, height = cm.shape\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            plt.annotate(str(cm[x][y]), xy=(y, x), \n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the multi-class problem can be solved near perfectly with XGBoost.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we saw in the binary and multi-class classification problems, XGBoost can be very effective at detecting anomalies when you have labeled data. In labs 2 and 3, we will consider the same KDD99 dataset but we will train deep learning models to detect anomalies without using the labels.  This will mimic a more likely situation is the real world.\n",
    "\n",
    "- GPU-Accelerating XGboost through RAPIDS is easy and fast.  The only change we had to make to use the GPU was to set the 'tree_method' parameter to 'gpu_hist'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "<li>\n",
    "Dhaliwal, S., Nahid, A., & Abbas, R. (2018). Effective Intrusion Detection System Using XGBoost. Information, 9(7), 149. doi:10.3390/info9070149\n",
    "</li>\n",
    "<li>\n",
    "Brownlee, J. A Gentle Introduction to XGBoost for Applied Machine Learning. Machine Learning\n",
    "Mastery. Available online: http://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/\n",
    "(accessed on 2 March 2018).\n",
    "    </li>\n",
    "    <li>A Study on NSL-KDD Dataset for Intrusion Detection System Based on Classification Algorithms. Available\n",
    "online: https://pdfs.semanticscholar.org/1b34/80021c4ab0f632efa99e01a9b073903c5554.pdf (accessed on\n",
    "        26 March 2018)</li>\n",
    "    <li>\n",
    "        XGBoost Parameters—Xgboost 0.7 Documentation. Available online: http://xgboost.readthedocs.io/en/\n",
    "latest/parameter.html (accessed on 12 March 2018)\n",
    "    </li>\n",
    "    <li>\n",
    "        RAPIDS Documentation and Cheat Sheet.Available online: https://rapids.ai/documentation.html\n",
    "    </li>\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"> <img src=\"images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
